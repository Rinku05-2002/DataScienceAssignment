{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1b90fe",
   "metadata": {},
   "source": [
    "# Statistics Advance - 1 (Assignment Questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d4662",
   "metadata": {},
   "source": [
    "## 1. Explain the properties of the F-distribution.\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "#### Properties of the F-Distribution\n",
    "\n",
    "The F-distribution is an important probability distribution in statistics, mainly used in hypothesis testing, ANOVA, and regression analysis. It is formed as the ratio of two independent chi-square variables, each divided by their respective degrees of freedom.\n",
    "\n",
    "**1. Definition**\n",
    "\n",
    "If $U_1 \\sim \\chi^2(d_1)$ and $U_2 \\sim \\chi^2(d_2)$, both independent, then the F-statistic is defined as:\n",
    "\n",
    "$$\n",
    "F = \\frac{(U_1 / d_1)}{(U_2 / d_2)}\n",
    "$$\n",
    "\n",
    "Here, $d_1$ is called the numerator degrees of freedom and $d_2$ is the denominator degrees of freedom.\n",
    "\n",
    "\n",
    "**2. Support**\n",
    "\n",
    "* The F-distribution takes only **non-negative values**.\n",
    "* Its range is:\n",
    "\n",
    "$$\n",
    "0 \\leq F < \\infty\n",
    "$$\n",
    "\n",
    "**3. Shape**\n",
    "\n",
    "* The shape depends on the values of $d_1$ and $d_2$.\n",
    "* For small degrees of freedom, the distribution is **highly skewed to the right**.\n",
    "* As $d_1$ and $d_2$ increase, the distribution becomes more **symmetric** and approaches the normal distribution.\n",
    "\n",
    "\n",
    "**4. Mean**\n",
    "\n",
    "* The mean exists only if $d_2 > 2$.\n",
    "\n",
    "$$\n",
    "E[F] = \\frac{d_2}{d_2 - 2}\n",
    "$$\n",
    "\n",
    "\n",
    "**5. Variance**\n",
    "\n",
    "* The variance exists only if $d_2 > 4$.\n",
    "\n",
    "$$\n",
    "Var(F) = \\frac{2 d_2^2 (d_1 + d_2 - 2)}{d_1 (d_2 - 2)^2 (d_2 - 4)}\n",
    "$$\n",
    "\n",
    "\n",
    "**6. Mode**\n",
    "\n",
    "* If $d_1 > 2$, the mode of the F-distribution is:\n",
    "\n",
    "$$\n",
    "Mode = \\frac{(d_1 - 2) d_2}{d_1 (d_2 + 2)}\n",
    "$$\n",
    "\n",
    "\n",
    "**7. Relation to Other Distributions**\n",
    "\n",
    "* If $F \\sim F(d_1, d_2)$, then its reciprocal also follows an F-distribution:\n",
    "\n",
    "$$\n",
    "\\frac{1}{F} \\sim F(d_2, d_1)\n",
    "$$\n",
    "\n",
    "* A connection with the t-distribution also exists:\n",
    "\n",
    "$$\n",
    "t_d^2 \\sim F(1, d)\n",
    "$$\n",
    "\n",
    "\n",
    "**8. Applications**\n",
    "\n",
    "The F-distribution is widely used in:\n",
    "\n",
    "* **Analysis of Variance (ANOVA):** to test whether group means are significantly different.\n",
    "* **Regression Analysis:** to test the overall significance of a regression model.\n",
    "* **Variance Comparison:** to test whether two populations have equal variances.\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The F-distribution is a continuous, non-negative, and right-skewed distribution. Its shape and properties depend on the degrees of freedom of the numerator and denominator. It is a fundamental tool in statistical hypothesis testing, especially in comparing variances and in ANOVA procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99ec31",
   "metadata": {},
   "source": [
    "## 2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Here’s a clean, **assignment-ready answer** for your question:\n",
    "\n",
    "---\n",
    "\n",
    "### Use of F-Distribution in Statistical Tests\n",
    "\n",
    "The F-distribution is mainly used in statistical tests that involve comparing **variances** or testing the **overall significance of models**. It is appropriate because it is based on the ratio of two independent estimates of variance, which makes it suitable for analyzing variability between groups or models.\n",
    "1. **Analysis of Variance (ANOVA)**\n",
    "\n",
    "* ANOVA uses the F-distribution to test whether the means of three or more groups are significantly different.\n",
    "* It works by comparing the **variance between groups** to the **variance within groups**.\n",
    "* If the calculated F-value is large, it suggests that the group means are not equal.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Regression Analysis**\n",
    "\n",
    "* In multiple regression, the F-test is used to check the **overall significance** of the model.\n",
    "* It compares the variation explained by the regression model with the variation due to error.\n",
    "* A significant F-value means that at least one predictor variable has a meaningful impact on the dependent variable.\n",
    "\n",
    "\n",
    " 3. **Test for Equality of Variances**\n",
    "\n",
    "* The F-distribution is used to compare the variances of two populations.\n",
    "* This is important when checking whether two datasets have the same variability, which is often an assumption in other statistical tests (like t-tests).\n",
    "\n",
    "\n",
    "**Why It Is Appropriate**\n",
    "\n",
    "* The F-distribution is always non-negative, which makes sense since variances are never negative.\n",
    "* It arises naturally as a ratio of variances, which is exactly what ANOVA, regression, and variance comparison require.\n",
    "* Its shape, which depends on degrees of freedom, allows it to adapt to different sample sizes and situations.\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The F-distribution is mainly used in **ANOVA, regression analysis, and tests of equality of variances**. It is appropriate for these tests because it provides a way to compare variances and assess the significance of models, making it a central tool in inferential statistics.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6081cce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f4475c6",
   "metadata": {},
   "source": [
    "## 3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?\n",
    "\n",
    "** Answer**\n",
    "\n",
    "**Key Assumptions for Conducting an F-Test to Compare Variances**\n",
    "\n",
    "When using the F-test to compare the variances of two populations, certain assumptions must be satisfied to ensure the test results are valid. These assumptions are:\n",
    "\n",
    "1. **Independence**\n",
    "\n",
    "* The two samples must be independent of each other.\n",
    "* This means that the data in one sample should not influence the data in the other sample.\n",
    "\n",
    "2. **Normality**\n",
    "\n",
    "* Each of the two populations should follow a **normal distribution**.\n",
    "* The F-test is highly sensitive to deviations from normality, so this assumption is very important.\n",
    "\n",
    "3. **Random Sampling**\n",
    "\n",
    "* The data should be collected using proper random sampling methods.\n",
    "* This ensures that the samples are representative of the populations being studied.\n",
    "\n",
    "4. **Scale of Measurement**\n",
    "\n",
    "* The data should be measured on at least an **interval or ratio scale**, so that variances are meaningful and can be compared.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The F-test for comparing two population variances assumes: **independent samples, normally distributed populations, random sampling, and interval/ratio scale of measurement**. If these assumptions are not met, the results of the test may not be reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7951e4b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad4b4bdd",
   "metadata": {},
   "source": [
    "## 4. What is the purpose of ANOVA, and how does it differ from a t-test? \n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Purpose of ANOVA and Its Difference from a t-test**\n",
    "\n",
    "**Purpose of ANOVA**\n",
    "\n",
    "* **ANOVA (Analysis of Variance)** is a statistical method used to test whether there are significant differences between the means of three or more groups.\n",
    "* It works by comparing the **variation between group means** with the **variation within the groups**.\n",
    "* The main goal of ANOVA is to determine whether at least one group mean is different, without having to perform multiple t-tests.\n",
    "\n",
    "\n",
    "**Difference Between ANOVA and t-test**\n",
    "\n",
    "1. **Number of Groups Compared**\n",
    "\n",
    "   * **t-test:** Used to compare the means of **two groups only**.\n",
    "   * **ANOVA:** Used to compare the means of **three or more groups**.\n",
    "\n",
    "2. **Error Control**\n",
    "\n",
    "   * **t-test:** If multiple t-tests are performed, the probability of making a Type I error (false positive) increases.\n",
    "   * **ANOVA:** Controls the overall error rate by testing all groups simultaneously in one test.\n",
    "\n",
    "3. **Test Statistic**\n",
    "\n",
    "   * **t-test:** Uses the **t-distribution** to compare means.\n",
    "   * **ANOVA:** Uses the **F-distribution** to compare variances between and within groups.\n",
    "\n",
    "4. **Result**\n",
    "\n",
    "   * **t-test:** Directly tells whether two groups differ in their means.\n",
    "   * **ANOVA:** Tells whether there is a significant difference among groups, but does not specify which groups differ. (Post-hoc tests are needed to find specific differences.)\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The purpose of ANOVA is to test for mean differences across three or more groups, while the t-test is limited to comparing only two groups. ANOVA is preferred when multiple groups are involved because it avoids increasing error rates and provides a more reliable overall comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f5af0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14a24243",
   "metadata": {},
   "source": [
    "## 5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n",
    "\n",
    "**Answer:**\n",
    "**When and Why to Use One-Way ANOVA Instead of Multiple t-tests**\n",
    "\n",
    "**When to Use One-Way ANOVA**\n",
    "\n",
    "* One-way ANOVA is used when we want to compare the **means of three or more independent groups** based on one independent variable (or factor).\n",
    "* Example: Comparing the average test scores of students taught by three different teaching methods.\n",
    "\n",
    "\n",
    "**Why One-Way ANOVA is Preferred Over Multiple t-tests**\n",
    "\n",
    "1. **Controls Type I Error Rate**\n",
    "\n",
    "   * If we perform multiple t-tests for several groups, the chance of making a **Type I error** (false positive) increases with each test.\n",
    "   * One-way ANOVA tests all groups at once, keeping the overall error rate under control.\n",
    "\n",
    "2. **More Efficient and Reliable**\n",
    "\n",
    "   * Instead of running many separate t-tests, ANOVA provides **one overall test** for group differences.\n",
    "   * This saves time and reduces complexity.\n",
    "\n",
    "3. **Uses Variance Information**\n",
    "\n",
    "   * ANOVA compares the **variance between group means** to the **variance within groups**, giving a more accurate picture of group differences.\n",
    "   * Multiple t-tests only compare groups in pairs, which may overlook the bigger picture.\n",
    "\n",
    "4. **Clearer Interpretation**\n",
    "\n",
    "   * ANOVA tells us whether there is **any significant difference** among the groups as a whole.\n",
    "   * If significant, post-hoc tests can then be applied to identify which specific groups differ.\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "One-way ANOVA is used instead of multiple t-tests when comparing more than two groups because it **controls error rates, is more efficient, and provides a reliable overall test of differences**. Multiple t-tests would increase the risk of false conclusions, while ANOVA ensures accurate and valid results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3fa3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d52ab27",
   "metadata": {},
   "source": [
    "## 6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Variance Partitioning in ANOVA and Its Role in the F-Statistic**\n",
    "**Partitioning of Variance in ANOVA**\n",
    "\n",
    "The main idea of ANOVA is to divide (or partition) the total variation in the data into two parts:\n",
    "\n",
    "1. **Between-Group Variance (Explained Variation)**\n",
    "\n",
    "   * This measures how much the group means differ from the overall mean.\n",
    "   * It represents variation due to the effect of the independent variable (the factor).\n",
    "   * If group means are very different from each other, the between-group variance will be large.\n",
    "\n",
    "2. **Within-Group Variance (Unexplained Variation or Error)**\n",
    "\n",
    "   * This measures the variation of individual scores around their own group mean.\n",
    "   * It represents random error or individual differences that are **not explained** by the independent variable.\n",
    "   * If the data points within each group are close to their group mean, the within-group variance will be small.\n",
    "\n",
    "\n",
    "**Relationship to the F-Statistic**\n",
    "\n",
    "* ANOVA uses these two sources of variance to calculate the **F-statistic**, which is the ratio of variances.\n",
    "\n",
    "$$\n",
    "F = \\frac{\\text{Between-group variance (Mean Square Between)}}{\\text{Within-group variance (Mean Square Within)}}\n",
    "$$\n",
    "\n",
    "* If the **between-group variance** is much larger than the **within-group variance**, it suggests that group means are not equal, and the independent variable has a significant effect.\n",
    "* If the ratio is close to 1, it means the differences between group means are small compared to the variability within groups, so the groups are likely not significantly different.\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "In ANOVA, total variance is partitioned into **between-group variance** (variation due to group differences) and **within-group variance** (variation due to random error). The F-statistic is then calculated as the ratio of these two variances, which helps determine whether the differences between group means are statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac44c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb8a67c9",
   "metadata": {},
   "source": [
    "## 7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Classical (Frequentist) vs. Bayesian Approaches to ANOVA**\n",
    "\n",
    "ANOVA can be performed using either the **classical frequentist approach** or the **Bayesian approach**. While both aim to test differences between group means, they differ in how they handle uncertainty, estimate parameters, and test hypotheses.\n",
    "\n",
    "\n",
    "**1. Treatment of Uncertainty**\n",
    "\n",
    "* **Frequentist ANOVA:**\n",
    "\n",
    "  * Uncertainty is expressed in terms of **long-run frequencies** of outcomes.\n",
    "  * Probabilities are attached to data, not to parameters.\n",
    "  * Example: A p-value shows the probability of obtaining results as extreme as the observed data, assuming the null hypothesis is true.\n",
    "\n",
    "* **Bayesian ANOVA:**\n",
    "\n",
    "  * Uncertainty is expressed directly in terms of **probabilities about parameters**.\n",
    "  * Probabilities are attached to hypotheses and parameters.\n",
    "  * Example: We can say there is a 90% probability that one group mean is greater than another, given the data.\n",
    "\n",
    "\n",
    "**2. Parameter Estimation**\n",
    "\n",
    "* **Frequentist ANOVA:**\n",
    "\n",
    "  * Parameters (like group means and variances) are treated as **fixed but unknown**.\n",
    "  * Estimates are obtained using sample data (e.g., mean squares), and confidence intervals are constructed.\n",
    "\n",
    "* **Bayesian ANOVA:**\n",
    "\n",
    "  * Parameters are treated as **random variables** with prior distributions.\n",
    "  * Estimates are updated using Bayes’ theorem, resulting in **posterior distributions**.\n",
    "  * Prior beliefs can influence the results.\n",
    "\n",
    "\n",
    "**3. Hypothesis Testing**\n",
    "\n",
    "* **Frequentist ANOVA:**\n",
    "\n",
    "  * Relies on the **F-statistic** and associated **p-value** to decide whether to reject the null hypothesis.\n",
    "  * Hypothesis testing is based on whether the observed data would be unlikely if the null hypothesis were true.\n",
    "\n",
    "* **Bayesian ANOVA:**\n",
    "\n",
    "  * Hypotheses are compared using **posterior probabilities** or **Bayes factors**.\n",
    "  * Provides a direct probability statement about which hypothesis is more likely, given the data.\n",
    "\n",
    "\n",
    "**Key Differences in Summary**\n",
    "\n",
    "| Aspect                 | Frequentist ANOVA                       | Bayesian ANOVA                                    |\n",
    "| ---------------------- | --------------------------------------- | ------------------------------------------------- |\n",
    "| **Uncertainty**        | Based on long-run frequency of outcomes | Expressed as probability of parameters/hypotheses |\n",
    "| **Parameters**         | Fixed but unknown                       | Random variables with prior distributions         |\n",
    "| **Estimation**         | Point estimates + confidence intervals  | Posterior distributions (updated beliefs)         |\n",
    "| **Hypothesis Testing** | Uses F-statistic and p-values           | Uses posterior probabilities or Bayes factors     |\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The **frequentist approach** focuses on testing hypotheses through p-values and F-statistics, while the **Bayesian approach** incorporates prior knowledge, produces posterior distributions, and allows probability statements about hypotheses. Both methods are useful, but the Bayesian approach provides a more intuitive interpretation of uncertainty.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39dfb8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c92426a9",
   "metadata": {},
   "source": [
    "## 8. Question: You have two sets of data representing the incomes of two different professions1\n",
    "##  Profession A: [48, 52, 55, 60, 62]\n",
    "##  Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test?\n",
    "\n",
    "## **Task:** Use Python to calculate the F-statistic and p-value for the given data.\n",
    "\n",
    "## Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Here’s the step-by-step solution and interpretation:\n",
    "\n",
    "\n",
    "**Data**\n",
    "\n",
    "* Profession A incomes: \\[48, 52, 55, 60, 62]\n",
    "* Profession B incomes: \\[45, 50, 55, 52, 47]\n",
    "\n",
    "\n",
    "**Step 1: Calculate Variances**\n",
    "\n",
    "* Variance of Profession A = **32.8**\n",
    "* Variance of Profession B = **15.7**\n",
    "\n",
    "\n",
    "**Step 2: Calculate F-statistic**\n",
    "\n",
    "We take the ratio of the larger variance to the smaller variance:\n",
    "\n",
    "$$\n",
    "F = \\frac{32.8}{15.7} \\approx 2.09\n",
    "$$\n",
    "\n",
    "Degrees of freedom:\n",
    "\n",
    "* $df_1 = 4$ (Profession A)\n",
    "* $df_2 = 4$ (Profession B)\n",
    "\n",
    "\n",
    "**Step 3: Find p-value**\n",
    "\n",
    "The two-tailed p-value from the F-distribution is:\n",
    "\n",
    "$$\n",
    "p \\approx 0.493\n",
    "$$\n",
    "\n",
    "\n",
    "**Step 4: Conclusion**\n",
    "\n",
    "* At a 5% significance level ($\\alpha = 0.05$), the p-value (0.493) is **much greater** than 0.05.\n",
    "* This means we **fail to reject the null hypothesis**.\n",
    "\n",
    "**Conclusion:** There is no significant difference between the variances of incomes in Profession A and Profession B.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65a95b",
   "metadata": {},
   "source": [
    "## 9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data:\n",
    "* Region A: [160, 162, 165, 158, 164]\n",
    "* Region B: [172, 175, 170, 168, 174]\n",
    "* Region C: [180, 182, 179, 185, 183]\n",
    "* Task: Write Python code to perform the one-way ANOVA and interpret the results.\n",
    "* Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n",
    "\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "\n",
    "**Data**\n",
    "\n",
    "* Region A heights: \\[160, 162, 165, 158, 164]\n",
    "* Region B heights: \\[172, 175, 170, 168, 174]\n",
    "* Region C heights: \\[180, 182, 179, 185, 183]\n",
    "\n",
    "\n",
    "**Step 1: Perform One-Way ANOVA**\n",
    "\n",
    "Using Python’s `scipy.stats.f_oneway`:\n",
    "\n",
    "* **F-statistic** = 67.87\n",
    "* **p-value** = 2.87 × 10⁻⁷\n",
    "\n",
    "\n",
    "**Step 2: Interpretation**\n",
    "\n",
    "* The p-value is **much smaller** than the usual significance level of 0.05.\n",
    "* This means we **reject the null hypothesis** (that all three regions have the same average height).\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "There are **statistically significant differences** in the average heights between Region A, Region B, and Region C."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
